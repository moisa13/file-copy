# File Copy Manager â€” EspecificaÃ§Ã£o TÃ©cnica Completa

## 1. VisÃ£o Geral

Sistema de cÃ³pia gerenciada de arquivos com fila de processamento, dashboard web, logging estruturado e persistÃªncia. Desenvolvido em **Node.js**.

### Objetivo

Copiar arquivos de **N pastas de origem** para **1 pasta de destino**, com controle total sobre o processo: fila com status, acompanhamento em tempo real, logs por canal, persistÃªncia contra quedas e controle operacional (pausar, retomar, configurar workers).

---

## 2. Arquitetura

```
file-copy-manager/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.js              # Entry point â€” inicializa tudo
â”‚   â”œâ”€â”€ config.js             # ConfiguraÃ§Ãµes centralizadas
â”‚   â”œâ”€â”€ queue/
â”‚   â”‚   â””â”€â”€ database.js       # PersistÃªncia com SQLite (better-sqlite3)
â”‚   â”œâ”€â”€ scanner/
â”‚   â”‚   â””â”€â”€ index.js          # Varredura recursiva das pastas de origem
â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â””â”€â”€ index.js          # Pool de workers para cÃ³pia paralela
â”‚   â”œâ”€â”€ logger/
â”‚   â”‚   â””â”€â”€ index.js          # Sistema de log multicanal com rotaÃ§Ã£o
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ index.js          # API REST + WebSocket (Express + ws)
â”œâ”€â”€ public/
â”‚   â””â”€â”€ index.html            # Dashboard SPA (HTML/CSS/JS inline)
â”œâ”€â”€ logs/                     # DiretÃ³rio de logs (criado automaticamente)
â”œâ”€â”€ data/                     # Banco SQLite (criado automaticamente)
â””â”€â”€ package.json
```

### DependÃªncias

```json
{
  "dependencies": {
    "express": "^4.18.2",
    "better-sqlite3": "^9.4.3",
    "ws": "^8.16.0",
    "rotating-file-stream": "^3.1.1"
  }
}
```

- **express**: API REST para o dashboard
- **better-sqlite3**: PersistÃªncia da fila em SQLite (sÃ­ncrono, sem overhead de ORM)
- **ws**: WebSocket para atualizaÃ§Ã£o em tempo real no dashboard
- **rotating-file-stream**: RotaÃ§Ã£o de logs por tamanho

---

## 3. ConfiguraÃ§Ã£o (`src/config.js`)

```javascript
const path = require('path');

module.exports = {
  // N pastas de origem
  sourceFolders: [
    // '/caminho/pasta/origem1',
    // '/caminho/pasta/origem2',
  ],

  // 1 pasta de destino
  destinationFolder: '',
  // '/caminho/pasta/destino',

  // Workers paralelos
  workers: {
    count: 4,       // PadrÃ£o inicial
    maxCount: 16,   // MÃ¡ximo permitido
  },

  // Logging
  logging: {
    directory: path.join(__dirname, '..', 'logs'),
    maxFileSize: '10M',   // RotaÃ§Ã£o a cada 10MB
    maxFiles: 50,         // Manter atÃ© 50 arquivos rotacionados
  },

  // PersistÃªncia SQLite
  database: {
    path: path.join(__dirname, '..', 'data', 'queue.db'),
  },

  // Dashboard
  server: {
    port: 3000,
    host: '0.0.0.0',
  },

  // Hash
  hashAlgorithm: 'sha256',

  // Scanner
  scanner: {
    recursive: true,
    ignorePatterns: ['.DS_Store', 'Thumbs.db', '.gitkeep'],
  },
};
```

---

## 4. PersistÃªncia â€” Banco de Dados (`src/queue/database.js`)

Usar **better-sqlite3** com modo WAL para performance e resistÃªncia a corrupÃ§Ã£o.

### Schema

```sql
CREATE TABLE IF NOT EXISTS file_queue (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  source_path TEXT NOT NULL,
  source_folder TEXT NOT NULL,
  relative_path TEXT NOT NULL,
  destination_path TEXT NOT NULL,
  file_size INTEGER DEFAULT 0,
  source_hash TEXT,
  destination_hash TEXT,
  status TEXT NOT NULL DEFAULT 'pending',
  error_message TEXT,
  created_at TEXT NOT NULL DEFAULT (datetime('now', 'localtime')),
  updated_at TEXT NOT NULL DEFAULT (datetime('now', 'localtime')),
  started_at TEXT,
  completed_at TEXT,
  worker_id INTEGER,
  UNIQUE(source_path, destination_path)
);

CREATE INDEX IF NOT EXISTS idx_status ON file_queue(status);
CREATE INDEX IF NOT EXISTS idx_source_folder ON file_queue(source_folder);

CREATE TABLE IF NOT EXISTS service_state (
  key TEXT PRIMARY KEY,
  value TEXT NOT NULL,
  updated_at TEXT NOT NULL DEFAULT (datetime('now', 'localtime'))
);
```

### Status possÃ­veis

| Status | DescriÃ§Ã£o |
|--------|-----------|
| `pending` | Aguardando processamento |
| `in_progress` | Sendo copiado por um worker |
| `completed` | CÃ³pia finalizada com sucesso |
| `error` | Falha na cÃ³pia (permissÃ£o, disco cheio, etc.) |
| `conflict` | Arquivo existe no destino com hash SHA-256 diferente |

### RecuperaÃ§Ã£o apÃ³s queda

Na inicializaÃ§Ã£o do banco, **SEMPRE** executar:

```sql
UPDATE file_queue
SET status = 'pending', worker_id = NULL, started_at = NULL,
    updated_at = datetime('now', 'localtime')
WHERE status = 'in_progress';
```

Isso garante que arquivos que estavam "em andamento" durante um crash voltem para a fila automaticamente.

### Estado do serviÃ§o

Persistir na tabela `service_state`:
- `serviceStatus`: `'running'` | `'paused'` | `'stopped'`
- `workerCount`: nÃºmero de workers ativos

Isso permite restaurar o estado operacional apÃ³s reinÃ­cio.

### MÃ©todos necessÃ¡rios

- `addFiles(files)` â€” InserÃ§Ã£o em batch com transaction
- `getNextPending(limit)` â€” Buscar prÃ³ximos N pendentes
- `updateStatus(id, status, extras)` â€” Atualizar status com campos opcionais (hash, erro, workerId, timestamps)
- `getStats()` â€” Contagem e tamanho total por status
- `getFilesByStatus(status, limit, offset)` â€” Listagem paginada por status
- `getRecentActivity(limit)` â€” Ãšltimas N atualizaÃ§Ãµes
- `resolveConflict(id, action)` â€” `'overwrite'` volta para pending, `'skip'` marca como completed
- `resolveAllConflicts(action)` â€” Resolver todos os conflitos de uma vez
- `retryError(id)` / `retryAllErrors()` â€” Recolocar erros na fila
- `getServiceState(key)` / `setServiceState(key, value)` â€” Persistir estado do serviÃ§o

---

## 5. Scanner de Arquivos (`src/scanner/index.js`)

### Comportamento

1. Iterar sobre cada pasta em `config.sourceFolders`
2. Varredura **recursiva** (incluindo subpastas)
3. Ignorar arquivos que casem com `config.scanner.ignorePatterns`
4. Para cada arquivo encontrado, calcular o `relativePath` em relaÃ§Ã£o Ã  pasta de origem
5. O `destinationPath` = `config.destinationFolder` + `relativePath` (preservando a estrutura de subpastas)
6. Inserir todos os arquivos no banco com status `pending` (usar `INSERT OR IGNORE` para nÃ£o duplicar)
7. Logar cada arquivo adicionado

### Dados coletados por arquivo

```javascript
{
  sourcePath: '/origem1/subpasta/arquivo.txt',     // Caminho absoluto de origem
  sourceFolder: '/origem1',                         // Pasta de origem base
  relativePath: 'subpasta/arquivo.txt',             // Caminho relativo
  destinationPath: '/destino/subpasta/arquivo.txt', // Caminho de destino
  fileSize: 1048576,                                // Tamanho em bytes (via fs.statSync)
}
```

---

## 6. Workers / Motor de CÃ³pia (`src/workers/index.js`)

### Pool de Workers

Usar um EventEmitter que gerencia N workers lÃ³gicos (nÃ£o threads reais â€” usar concorrÃªncia async com promises).

### Fluxo de cada worker

```
1. Buscar prÃ³ximo arquivo "pending" no banco
2. Marcar como "in_progress" (com worker_id)
3. Verificar se o arquivo jÃ¡ existe no destino:
   a. Se NÃƒO existe â†’ copiar
   b. Se existe:
      - Calcular hash SHA-256 da origem
      - Calcular hash SHA-256 do destino
      - Se hashes iguais â†’ marcar como "completed" (jÃ¡ estÃ¡ lÃ¡, idÃªntico)
      - Se hashes diferentes â†’ marcar como "conflict" (aguardar decisÃ£o manual)
4. Executar a cÃ³pia:
   - Criar diretÃ³rios intermediÃ¡rios no destino (fs.mkdirSync recursive)
   - Copiar usando streams (fs.createReadStream â†’ fs.createWriteStream)
   - Calcular hash SHA-256 durante a leitura do stream (crypto.createHash)
5. ApÃ³s cÃ³pia, verificar integridade:
   - Calcular hash do arquivo copiado
   - Comparar com hash da origem
   - Se igual â†’ marcar como "completed"
   - Se diferente â†’ marcar como "error" (falha de integridade)
6. Em caso de exceÃ§Ã£o â†’ marcar como "error" com mensagem
7. Logar toda transiÃ§Ã£o de status
8. Emitir evento para o WebSocket atualizar o dashboard
```

### CÃ³pia com stream e hash simultÃ¢neo

```javascript
async function copyFileWithHash(sourcePath, destinationPath) {
  const dir = path.dirname(destinationPath);
  fs.mkdirSync(dir, { recursive: true });

  return new Promise((resolve, reject) => {
    const hash = crypto.createHash('sha256');
    const readStream = fs.createReadStream(sourcePath);
    const writeStream = fs.createWriteStream(destinationPath);

    readStream.on('data', (chunk) => hash.update(chunk));
    readStream.pipe(writeStream);

    writeStream.on('finish', () => resolve(hash.digest('hex')));
    writeStream.on('error', reject);
    readStream.on('error', reject);
  });
}
```

### CÃ¡lculo de hash de arquivo existente

```javascript
async function computeFileHash(filePath) {
  return new Promise((resolve, reject) => {
    const hash = crypto.createHash('sha256');
    const stream = fs.createReadStream(filePath);
    stream.on('data', (chunk) => hash.update(chunk));
    stream.on('end', () => resolve(hash.digest('hex')));
    stream.on('error', reject);
  });
}
```

### Controles

- `start()` â€” Inicia o processamento
- `pause()` â€” Para de puxar novos arquivos (workers ativos terminam o arquivo atual)
- `resume()` â€” Retoma o processamento
- `stop()` â€” Para tudo
- `setWorkerCount(n)` â€” Altera nÃºmero de workers (mÃ­nimo 1, mÃ¡ximo `config.workers.maxCount`)

### Loop de processamento

Usar um loop com `setTimeout` para nÃ£o bloquear o event loop:

```
_processLoop():
  - Se pausado ou parado â†’ retornar
  - Calcular slots disponÃ­veis = workerCount - activeWorkers
  - Se slots > 0 â†’ buscar N pendentes do banco â†’ processar cada um em paralelo
  - Agendar prÃ³ximo check em 200ms
```

---

## 7. Sistema de Logging (`src/logger/index.js`)

### Canais de log

| Canal | Arquivo | ConteÃºdo |
|-------|---------|----------|
| `geral` | `geral.log` | Todas as operaÃ§Ãµes |
| `pendente` | `pendente.log` | Arquivos adicionados Ã  fila |
| `em_andamento` | `em_andamento.log` | InÃ­cio de cÃ³pia |
| `erro` | `erro.log` | Falhas de cÃ³pia |
| `conflito` | `conflito.log` | Conflitos detectados |
| `finalizado` | `finalizado.log` | CÃ³pias concluÃ­das |

### Formato de cada entrada

```
[2026-02-13T14:30:00.000Z] [STATUS] [Worker:2] Arquivo: /origem/doc.pdf | Origem: /origem | Tamanho: 15.20 MB | Hash: abc123... | Mensagem adicional
```

### Campos obrigatÃ³rios

- **Timestamp**: ISO 8601
- **Status**: PENDING, IN_PROGRESS, COMPLETED, ERROR, CONFLICT
- **Worker ID**: Qual worker processou
- **Arquivo**: Caminho completo de origem
- **Pasta de origem**: Pasta base
- **Tamanho**: Formatado (ex: "15.20 MB") + valor em bytes
- **Hash**: SHA-256 (quando disponÃ­vel)
- **Mensagem de erro**: Quando aplicÃ¡vel

### RotaÃ§Ã£o

Usar `rotating-file-stream` com rotaÃ§Ã£o por tamanho (`10M`). Nomenclatura rotacionada: `{canal}-{data}-{indice}.log`.

### Regra de escrita

Toda entrada Ã© escrita em **dois canais simultaneamente**:
1. Canal **geral** (sempre)
2. Canal **especÃ­fico do status** (sempre)

---

## 8. API REST (`src/api/index.js`)

Usar **Express** para a API e **ws** para WebSocket.

### Endpoints

| MÃ©todo | Rota | DescriÃ§Ã£o |
|--------|------|-----------|
| `GET` | `/api/stats` | EstatÃ­sticas gerais (contadores por status) |
| `GET` | `/api/files/:status` | Listar arquivos por status (query: `?limit=100&offset=0`) |
| `GET` | `/api/activity` | Ãšltimas 50 atualizaÃ§Ãµes |
| `GET` | `/api/service` | Estado do serviÃ§o (status, workers) |
| `POST` | `/api/service/start` | Iniciar processamento |
| `POST` | `/api/service/pause` | Pausar processamento |
| `POST` | `/api/service/resume` | Retomar processamento |
| `POST` | `/api/service/stop` | Parar processamento |
| `POST` | `/api/service/workers` | Alterar nÂº de workers (body: `{ "count": 8 }`) |
| `POST` | `/api/scan` | Executar nova varredura das pastas de origem |
| `POST` | `/api/conflicts/:id/resolve` | Resolver conflito individual (body: `{ "action": "overwrite" \| "skip" }`) |
| `POST` | `/api/conflicts/resolve-all` | Resolver todos os conflitos (body: `{ "action": "overwrite" \| "skip" }`) |
| `POST` | `/api/errors/:id/retry` | Retentar cÃ³pia de um arquivo com erro |
| `POST` | `/api/errors/retry-all` | Retentar todos os erros |

### WebSocket

Endpoint: `ws://host:port` (upgrade no mesmo servidor HTTP)

O servidor emite eventos JSON para todos os clientes conectados:

```json
{
  "event": "status-update",
  "data": {
    "fileId": 123,
    "status": "completed",
    "sourcePath": "/origem/arquivo.txt",
    "timestamp": "2026-02-13T14:30:00.000Z"
  }
}
```

```json
{
  "event": "stats-update",
  "data": {
    "pending": { "count": 45, "totalSize": 1073741824 },
    "in_progress": { "count": 4, "totalSize": 52428800 },
    "completed": { "count": 150, "totalSize": 5368709120 },
    "error": { "count": 2, "totalSize": 2097152 },
    "conflict": { "count": 3, "totalSize": 15728640 }
  }
}
```

```json
{
  "event": "service-update",
  "data": {
    "status": "running",
    "workerCount": 4,
    "activeWorkers": 3
  }
}
```

Emitir `stats-update` a cada transiÃ§Ã£o de status de arquivo e periodicamente (a cada 2 segundos).

---

## 9. Dashboard Web (`public/index.html`)

Arquivo HTML Ãºnico (SPA) com CSS e JS inline. **Sem autenticaÃ§Ã£o.** Sem frameworks â€” vanilla JS.

### Layout do Dashboard

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FILE COPY MANAGER                          [Status: â—]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Pendentesâ”‚ â”‚Em Andam. â”‚ â”‚  Erros   â”‚ â”‚Conflitos â”‚   â”‚
â”‚  â”‚   45     â”‚ â”‚    4     â”‚ â”‚    2     â”‚ â”‚    3     â”‚   â”‚
â”‚  â”‚ 1.0 GB   â”‚ â”‚ 50 MB    â”‚ â”‚ 2 MB     â”‚ â”‚ 15 MB    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚Finalizad.â”‚   Progresso Total: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 73.5%       â”‚
â”‚  â”‚  150     â”‚                                           â”‚
â”‚  â”‚ 5.0 GB   â”‚                                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚                                                          â”‚
â”œâ”€â”€â”€â”€ CONTROLES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  [â–¶ Iniciar] [â¸ Pausar] [â¹ Parar] [ğŸ”„ Re-escanear]    â”‚
â”‚                                                          â”‚
â”‚  Workers: [  4  ] [Aplicar]                              â”‚
â”‚                                                          â”‚
â”‚  Conflitos: [Sobrescrever Todos] [Pular Todos]           â”‚
â”‚  Erros:     [Retentar Todos]                             â”‚
â”‚                                                          â”‚
â”œâ”€â”€â”€â”€ TABELA DE ARQUIVOS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  Filtro: [Todos â–¼] [Pendentes] [Em And.] [Erros]        â”‚
â”‚          [Conflitos] [Finalizados]                       â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ ID â”‚ Arquivo          â”‚ Origem   â”‚Tamanho â”‚ Status  â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ 1  â”‚ doc.pdf          â”‚ /orig1   â”‚ 15 MB  â”‚ âœ… OK   â”‚ â”‚
â”‚  â”‚ 2  â”‚ foto.jpg         â”‚ /orig2   â”‚ 3 MB   â”‚ âš  Conf. â”‚ â”‚
â”‚  â”‚ 3  â”‚ data.csv         â”‚ /orig1   â”‚ 500 KB â”‚ âŒ Erro â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                          â”‚
â”‚  Na linha de conflito: botÃµes [Sobrescrever] [Pular]     â”‚
â”‚  Na linha de erro: botÃ£o [Retentar]                      â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Funcionalidades do Dashboard

1. **Cards de status**: Contadores com totais em tamanho por status, atualizados via WebSocket
2. **Barra de progresso geral**: `(completed / total) * 100`
3. **Controles do serviÃ§o**: BotÃµes para iniciar, pausar, retomar, parar
4. **ConfiguraÃ§Ã£o de workers**: Input numÃ©rico + botÃ£o aplicar
5. **ResoluÃ§Ã£o em massa**: BotÃµes para resolver todos os conflitos ou retentar todos os erros
6. **Tabela de arquivos**: FiltrÃ¡vel por status, com aÃ§Ãµes inline (resolver conflito, retentar erro)
7. **Indicador de conexÃ£o WebSocket**: Mostrar se estÃ¡ conectado ao servidor
8. **Auto-reconnect WebSocket**: Reconectar automaticamente se a conexÃ£o cair

### Estilo visual

- Design escuro (dark theme) com cores distintas por status:
  - Pendente: azul (`#3b82f6`)
  - Em Andamento: amarelo (`#f59e0b`)
  - Finalizado: verde (`#10b981`)
  - Erro: vermelho (`#ef4444`)
  - Conflito: laranja (`#f97316`)
- Tipografia limpa e legÃ­vel, fonte monospace para dados
- Layout responsivo

---

## 10. Entry Point (`src/index.js`)

### Fluxo de inicializaÃ§Ã£o

```
1. Carregar config
2. Validar configuraÃ§Ãµes (pastas existem, destino Ã© gravÃ¡vel)
3. Inicializar banco de dados (SQLite) â†’ recuperaÃ§Ã£o automÃ¡tica de crash
4. Inicializar logger
5. Restaurar estado do serviÃ§o (workerCount salvo, etc.)
6. Executar varredura inicial das pastas de origem
7. Inicializar servidor Express + WebSocket
8. Servir dashboard em GET /
9. Registrar rotas da API
10. Iniciar pool de workers (se estado anterior era 'running')
11. Logar inÃ­cio do sistema
12. Tratar SIGINT/SIGTERM para shutdown graceful
```

### Shutdown graceful

Ao receber SIGINT ou SIGTERM:
1. Parar de aceitar novos arquivos
2. Aguardar workers ativos finalizarem o arquivo atual
3. Salvar estado no banco
4. Fechar streams de log
5. Fechar banco de dados
6. Encerrar processo

---

## 11. Regras de NegÃ³cio Importantes

### Conflitos

- Um conflito Ã© detectado quando: o arquivo **jÃ¡ existe no destino** E o hash SHA-256 do arquivo de origem Ã© **diferente** do hash do arquivo no destino
- Se o hash for **igual**: marcar como `completed` sem copiar (o arquivo jÃ¡ estÃ¡ lÃ¡, idÃªntico)
- Conflitos ficam **parados na fila** atÃ© decisÃ£o manual via dashboard
- AÃ§Ãµes possÃ­veis: `overwrite` (sobrescrever â€” volta para `pending` e serÃ¡ copiado) ou `skip` (pular â€” marca como `completed`)

### Estrutura de diretÃ³rios no destino

- Manter a mesma estrutura de subpastas da origem
- Se a origem Ã© `/orig1/subpasta/arquivo.txt`, o destino deve ser `/destino/subpasta/arquivo.txt`
- Criar diretÃ³rios intermediÃ¡rios automaticamente com `fs.mkdirSync(dir, { recursive: true })`

### Integridade pÃ³s-cÃ³pia

- ApÃ³s copiar, calcular hash do arquivo no destino
- Comparar com hash da origem
- Se diferente â†’ marcar como `error` com mensagem "Falha de integridade: hash pÃ³s-cÃ³pia nÃ£o confere"

### DeduplicaÃ§Ã£o

- `UNIQUE(source_path, destination_path)` no banco impede que o mesmo arquivo seja enfileirado duas vezes
- Novas varreduras (`POST /api/scan`) apenas adicionam arquivos novos, nÃ£o duplicam os existentes

---

## 12. Resumo dos Comandos para Setup

```bash
# Criar o projeto
mkdir file-copy-manager && cd file-copy-manager
npm init -y
npm install express better-sqlite3 ws rotating-file-stream

# Criar estrutura
mkdir -p src/{queue,scanner,workers,logger,api} public logs data

# ApÃ³s implementar tudo:
node src/index.js
# Dashboard disponÃ­vel em http://localhost:3000
```

---

## 13. Checklist de ImplementaÃ§Ã£o

- [ ] `package.json` com dependÃªncias
- [ ] `src/config.js` â€” ConfiguraÃ§Ãµes centralizadas
- [ ] `src/queue/database.js` â€” SQLite com schema, CRUD, recuperaÃ§Ã£o de crash
- [ ] `src/scanner/index.js` â€” Varredura recursiva + enfileiramento
- [ ] `src/workers/index.js` â€” Pool de workers async com cÃ³pia+hash via streams
- [ ] `src/logger/index.js` â€” 6 canais de log com rotaÃ§Ã£o por tamanho
- [ ] `src/api/index.js` â€” Express REST + WebSocket
- [ ] `public/index.html` â€” Dashboard SPA completo
- [ ] `src/index.js` â€” Entry point com inicializaÃ§Ã£o e shutdown graceful
- [ ] Testar recuperaÃ§Ã£o apÃ³s kill -9
- [ ] Testar conflitos (copiar arquivo, modificar destino, re-escanear)
- [ ] Testar alteraÃ§Ã£o de workers em tempo real
- [ ] Testar pausar/retomar
